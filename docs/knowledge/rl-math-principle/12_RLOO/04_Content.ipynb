{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RLOO算法：交互式演示\n",
        "\n",
        "我们将演示如何通过向量化操作高效计算Leave-One-Out基线。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 模拟数据\n",
        "假设Batch=2, Group Size=4。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards = torch.tensor([\n",
        "    [10.0, 5.0, 8.0, 2.0],  # Prompt 1\n",
        "    [1.0,  1.0, 1.0, 5.0]   # Prompt 2\n",
        "])\n",
        "print(\"Rewards shape:\", rewards.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 计算总和 (Row Sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum_rewards = rewards.sum(dim=1, keepdim=True)\n",
        "print(\"Sum rewards:\\n\", sum_rewards)\n",
        "# 预期: \n",
        "# [[25.],\n",
        "#  [ 8.]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 计算留一均值 (LOO Mean)\n",
        "$$b_i = \\frac{\\text{Sum} - R_i}{G - 1}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = 4\n",
        "loo_means = (sum_rewards - rewards) / (G - 1)\n",
        "print(\"LOO Means:\\n\", loo_means)\n",
        "\n",
        "# 验证 Prompt 1, Response 0 (Reward=10):\n",
        "# Expected Baseline = (5+8+2)/3 = 5.0\n",
        "print(\"\\nCheck P1_R0: Expected=5.0, Actual=\", loo_means[0, 0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 计算优势 (Advantage)\n",
        "$$A_i = R_i - b_i$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "advantages = rewards - loo_means\n",
        "print(\"Advantages:\\n\", advantages)\n",
        "\n",
        "# 验证 P1_R0 (Reward=10, Baseline=5):\n",
        "# Expected Adv = 5.0\n",
        "print(\"\\nCheck P1_R0 Adv: Expected=5.0, Actual=\", advantages[0,0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 对此GRPO\n",
        "GRPO使用包含自身的均值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grpo_mean = rewards.mean(dim=1, keepdim=True)\n",
        "print(\"GRPO Mean (P1):\", grpo_mean[0].item())\n",
        "# P1 Mean = 25/4 = 6.25\n",
        "\n",
        "grpo_adv = rewards - grpo_mean\n",
        "print(\"GRPO Adv (P1_R0):\", grpo_adv[0,0].item())\n",
        "# 10 - 6.25 = 3.75\n",
        "\n",
        "print(\"\\n对比:\")\n",
        "print(\"RLOO Adv:\", advantages[0,0].item(), \" (更强烈)\")\n",
        "print(\"GRPO Adv:\", grpo_adv[0,0].item(), \" (被自身拉低)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
