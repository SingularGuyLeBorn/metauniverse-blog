### 1. 核心思想: 结构化的海量并行

GPU的强大计算能力源于其并行执行数千个线程的能力. 然而, 这种并行并非无政府状态的混乱. GPU执行模型提供了一套结构化的、层次化的抽象, 让程序员能够有效地组织和管理这些海量的线程. 这个模型的核心是三个概念: **线程 (Thread)**,**线程束 (Warp)**, 和**线程块 (Block)**. 理解它们之间的关系以及它们如何映射到硬件上, 是解锁GPU性能的关键.

![GPU执行模型示意图](https://storage.googleapis.com/static.slab.com/prod/uploads/7d890538/posts/images/1oQ9_wI15wO5v-G6_Z6-r41Q.png)
> 图1: 一个CUDA程序被组织成一个网格 (Grid), 网格由线程块 (Blocks) 组成. 每个块被分配到一个SM上. 在SM内部, 块内的线程被分组为线程束 (Warps) 来执行.

### 2. 执行模型的三个层次

#### a. 线程 (Thread)

- **定义**: 线程是执行计算的最小单位. 每个线程都有自己的程序计数器、寄存器和私有的本地内存.
- **工作方式**: 在一个kernel中, 所有线程都执行相同的代码, 但它们通过唯一的ID (如`threadIdx.x`) 来区分彼此, 从而可以处理不同的数据. 这就是所谓的**SIMT (Single Instruction, Multiple Thread)**模型.

#### b. 线程块 (Block)

- **定义**: 线程块是一组线程的集合. 它们可以是一维、二维或三维的.
- **协作**: 同一个线程块内的所有线程都在同一个**流式多处理器 (SM)**上执行. 这使得它们能够通过快速的**共享内存 (Shared Memory)**进行协作和数据交换, 并且可以通过**同步障 (synchronization barriers, `__syncthreads()`)**进行同步.
- **资源独立**: 每个线程块有自己独立的资源, 如共享内存. 一个块的共享内存对其他块是不可见的.
- **调度**: 整个kernel的工作被划分为一个由许多线程块组成的**网格 (Grid)**. GPU的硬件调度器负责将这些线程块分配到可用的SM上执行. 各个线程块的执行顺序是不保证的.

#### c. 线程束 (Warp)

- **定义**: 线程束是GPU硬件执行调度的基本单位. 它是由**32个连续的线程**组成的一组. 线程块内的线程会被硬件自动划分为多个线程束.
- **SIMT执行的核心**: 在一个时钟周期内, 一个SM上的一个Warp调度器会选择一个线程束, 并向其32个线程发出**相同的指令**. 这32个线程会同时执行这条指令, 但各自操作自己的数据 (通常存储在各自的寄存器中).
- **锁步执行 (Lock-step Execution)**: 一个线程束内的所有线程在概念上是同步执行的. 它们一起开始, 一起前进, 一起结束 (除非发生分歧).

### 3. 控制流分歧 (Control Divergence)

SIMT模型最需要注意的复杂性之一是**控制流分歧**.

- **发生场景**: 当一个线程束内的线程遇到条件分支 (如`if-else`), 并且根据各自的数据走向了不同的代码路径时, 就会发生分歧.
- **硬件处理**: GPU硬件无法同时执行`if`和`else`两个分支. 它会串行化这个过程:
    1.  硬件会先执行`if`分支, 此时所有走向`else`分支的线程会被**禁用 (masked out)**, 处于空闲状态.
    2.  `if`分支执行完毕后, 硬件会再执行`else`分支, 此时之前执行`if`分支的线程会被禁用.
- **性能影响**: 最终, 执行该条件分支的总时间是两个分支执行时间之和. 如果分歧严重 (例如, 16个线程走if, 16个走else), 线程束的计算效率会下降一半. 因此, 在编写高性能kernel时, 一个重要的目标是尽量避免或减少线程束内的分歧.

![控制流分歧的执行示意图](https://storage.googleapis.com/static.slab.com/prod/uploads/7d890538/posts/images/wYI8z7-e-j5-M6-i_V7M-g8c.png)
> 图2: 当线程束遇到if-else分支时, 硬件会依次执行每个分支路径, 并禁用 (mask) 那些不走该路径的线程, 导致性能下降.

### 4. 总结与编程启示

- **层次化思考**: 编写GPU程序时, 必须以Block和Thread的层次结构来思考问题. 通常, 你会将数据划分成由Block处理的块, 然后在Block内部, 每个Thread处理块中的一个元素.
- **善用共享内存**: 线程块内的协作是性能的关键. 利用共享内存来缓存从全局内存中读取的数据, 可以极大地提高数据重用率, 这是**平铺 (Tiling)**等高级优化的核心.
- **关注线程束**: 虽然程序员不能直接控制线程束, 但必须理解它的行为. 优化内存访问模式以实现**合并访问 (Coalesced Access)**, 以及组织数据和计算以**避免线程束分歧**, 是从“能运行”到“跑得快”的必经之路.
- **独立性**: 线程块之间是相互独立的. 你永远不能假设一个块会在另一个块之前或之后执行, 也不能让它们直接通信 (除非使用代价高昂的全局同步). 这种独立性使得GPU能够轻松地将成千上万的线程块调度到数百个SM上, 实现大规模并行.