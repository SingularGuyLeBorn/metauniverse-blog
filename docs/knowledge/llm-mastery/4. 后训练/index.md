---
title: 后训练
---

# 后训练

本章讲解大语言模型的后训练技术，包括 SFT、RLHF 和各种对齐方法。

## 章节导航

- **4.1 监督微调 (SFT)** - 指令微调、数据构建
- **4.2 奖励模型** - 偏好学习、奖励建模
- **4.3 强化学习** - PPO、DPO 等对齐算法
- **4.4 对齐技术** - 基于奖励/无奖励的对齐方法
